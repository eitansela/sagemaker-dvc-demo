{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Track ML experimentation using Amazon SageMaker Experiment & DVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contents \n",
    "\n",
    "1. [Background]\n",
    "2. [Setup]\n",
    "3. [Data]\n",
    "4. [Experiment 1]\n",
    "5. [Experiement 2]\n",
    "6. [Compare the experiments]\n",
    "7. [Move to a different data version]\n",
    "8. [Conclusion]\n",
    "9. [Refrence]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to demonstrate how to integrate Amazon SageMaker experiment with DVC to keep track of data and model during the ML experimentation phase. For the purpose of this demo, we just use customer churn use case as built in reference [1].  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's start with the initial setup which includes:\n",
    "    - Setup dvc and git for this notebook\n",
    "    - Import the required python packages\n",
    "    - Initiate the SageMaker session\n",
    "    - Get the IAM role for SageMaker\n",
    "    - Provide The S3 bucket name which will be used to store the data and DVC artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dvc in /opt/conda/lib/python3.7/site-packages (1.6.1)\n",
      "Requirement already satisfied: tabulate>=0.8.7 in /opt/conda/lib/python3.7/site-packages (from dvc) (0.8.7)\n",
      "Requirement already satisfied: configobj>=5.0.6 in /opt/conda/lib/python3.7/site-packages (from dvc) (5.0.6)\n",
      "Requirement already satisfied: distro>=1.3.0 in /opt/conda/lib/python3.7/site-packages (from dvc) (1.5.0)\n",
      "Requirement already satisfied: colorama>=0.3.9 in /opt/conda/lib/python3.7/site-packages (from dvc) (0.4.3)\n",
      "Requirement already satisfied: networkx<2.5,>=2.1 in /opt/conda/lib/python3.7/site-packages (from dvc) (2.4)\n",
      "Requirement already satisfied: requests>=2.22.0 in /opt/conda/lib/python3.7/site-packages (from dvc) (2.22.0)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.7/site-packages (from dvc) (1.4.4)\n",
      "Requirement already satisfied: jsonpath-ng>=1.5.1 in /opt/conda/lib/python3.7/site-packages (from dvc) (1.5.1)\n",
      "Requirement already satisfied: pyasn1>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from dvc) (0.4.8)\n",
      "Requirement already satisfied: grandalf==0.6 in /opt/conda/lib/python3.7/site-packages (from dvc) (0.6)\n",
      "Requirement already satisfied: tqdm<5,>=4.45.0 in /opt/conda/lib/python3.7/site-packages (from dvc) (4.48.2)\n",
      "Requirement already satisfied: funcy>=1.14 in /opt/conda/lib/python3.7/site-packages (from dvc) (1.14)\n",
      "Requirement already satisfied: pydot>=1.2.4 in /opt/conda/lib/python3.7/site-packages (from dvc) (1.4.1)\n",
      "Requirement already satisfied: ply>=3.9 in /opt/conda/lib/python3.7/site-packages (from dvc) (3.11)\n",
      "Requirement already satisfied: flatten-json<0.1.8,>=0.1.6 in /opt/conda/lib/python3.7/site-packages (from dvc) (0.1.7)\n",
      "Requirement already satisfied: pygtrie==2.3.2 in /opt/conda/lib/python3.7/site-packages (from dvc) (2.3.2)\n",
      "Requirement already satisfied: packaging>=19.0 in /opt/conda/lib/python3.7/site-packages (from dvc) (20.1)\n",
      "Requirement already satisfied: dpath<3,>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from dvc) (2.0.1)\n",
      "Requirement already satisfied: shortuuid>=0.5.0 in /opt/conda/lib/python3.7/site-packages (from dvc) (1.0.1)\n",
      "Requirement already satisfied: gitpython>3 in /opt/conda/lib/python3.7/site-packages (from dvc) (3.1.7)\n",
      "Requirement already satisfied: ruamel.yaml>=0.16.1 in /opt/conda/lib/python3.7/site-packages (from dvc) (0.16.10)\n",
      "Requirement already satisfied: rich>=3.0.5 in /opt/conda/lib/python3.7/site-packages (from dvc) (6.0.0)\n",
      "Requirement already satisfied: shtab<2,>=1.3.0 in /opt/conda/lib/python3.7/site-packages (from dvc) (1.3.1)\n",
      "Requirement already satisfied: setuptools>=34.0.0 in /opt/conda/lib/python3.7/site-packages (from dvc) (45.2.0.post20200210)\n",
      "Requirement already satisfied: pathspec>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from dvc) (0.8.0)\n",
      "Requirement already satisfied: nanotime>=0.5.2 in /opt/conda/lib/python3.7/site-packages (from dvc) (0.5.2)\n",
      "Requirement already satisfied: zc.lockfile>=1.2.1 in /opt/conda/lib/python3.7/site-packages (from dvc) (2.0)\n",
      "Requirement already satisfied: flufl.lock<4,>=3.2 in /opt/conda/lib/python3.7/site-packages (from dvc) (3.2)\n",
      "Requirement already satisfied: voluptuous>=0.11.7 in /opt/conda/lib/python3.7/site-packages (from dvc) (0.11.7)\n",
      "Requirement already satisfied: toml>=0.10.1 in /opt/conda/lib/python3.7/site-packages (from dvc) (0.10.1)\n",
      "Requirement already satisfied: dictdiffer>=0.8.1 in /opt/conda/lib/python3.7/site-packages (from dvc) (0.8.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from configobj>=5.0.6->dvc) (1.14.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from networkx<2.5,>=2.1->dvc) (4.4.1)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests>=2.22.0->dvc) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.22.0->dvc) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.22.0->dvc) (2019.11.28)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.22.0->dvc) (1.25.8)\n",
      "Requirement already satisfied: pyparsing in /opt/conda/lib/python3.7/site-packages (from grandalf==0.6->dvc) (2.4.6)\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from grandalf==0.6->dvc) (0.18.2)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.7/site-packages (from gitpython>3->dvc) (4.0.5)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.1.2; platform_python_implementation == \"CPython\" and python_version < \"3.9\" in /opt/conda/lib/python3.7/site-packages (from ruamel.yaml>=0.16.1->dvc) (0.2.0)\n",
      "Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in /opt/conda/lib/python3.7/site-packages (from rich>=3.0.5->dvc) (0.9.1)\n",
      "Requirement already satisfied: typing-extensions<4.0.0,>=3.7.4 in /opt/conda/lib/python3.7/site-packages (from rich>=3.0.5->dvc) (3.7.4.3)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /opt/conda/lib/python3.7/site-packages (from rich>=3.0.5->dvc) (2.6.1)\n",
      "Requirement already satisfied: atpublic in /opt/conda/lib/python3.7/site-packages (from flufl.lock<4,>=3.2->dvc) (2.0)\n",
      "Requirement already satisfied: smmap<4,>=3.0.1 in /opt/conda/lib/python3.7/site-packages (from gitdb<5,>=4.0.1->gitpython>3->dvc) (3.0.4)\n",
      "\u001b[31mERROR\u001b[39m: failed to install DVC Git hooks - Hook 'post-checkout' already exists. Please refer to <\u001b[36mhttps://man.dvc.org/install\u001b[39m> for more info.\n",
      "\n",
      "\u001b[33mHaving any troubles?\u001b[39m Hit us up at \u001b[34mhttps://dvc.org/support\u001b[39m, we are always happy to help!\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# install dvc (dvc version 1.6.4 is used in this demo) \n",
    "! pip install dvc \n",
    "# setup giet\n",
    "! git config --global user.name \"USERNAME\"   # Replace USERNAME with your source control user name\n",
    "! git config --global user.email \"EMAIL\"          # Replace EMAIL with your source control email\n",
    "\n",
    "# install dvc git hook (Ignore error if DVC Git hooks already exist)\n",
    "! dvc install\n",
    "\n",
    "# install sagemaker-experiments if required\n",
    "! pip install sagemaker-experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "from IPython.display import display\n",
    "from time import strftime, gmtime\n",
    "import sagemaker\n",
    "import boto3\n",
    "import re\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.predictor import csv_serializer\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "from smexperiments import experiment\n",
    "from smexperiments.trial_component import TrialComponent\n",
    "from smexperiments.tracker import Tracker\n",
    "from sagemaker import analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate the sagemaker session\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "# Define IAM role\n",
    "\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "bucket='BUCKETNAME'  # Replace with your bucket name\n",
    "prefix ='sagemaker'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the public dataset attributed to University of California Irvine Repository of Machine Learning Datasets. Let's download this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget http://dataminingconsultant.com/DKD2e_data_sets.zip\n",
    "!unzip -o DKD2e_data_sets.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn = pd.read_csv('./Data sets/churn.txt')\n",
    "pd.set_option('display.max_columns', 500)\n",
    "churn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset includes 3333 records and 21 attributes. The attributes are:\n",
    "\n",
    "- State: the US state (two-letter abbreviation) in which the customer resides,\n",
    "- Account Length: the number of days that this account has been active\n",
    "- Area Code: area code of the corresponding customer’s number\n",
    "- Phone: phone number\n",
    "- Int’l Plan: whether the customer has an international calling plan\n",
    "- VMail Plan: whether the customer has a voice mail feature\n",
    "- VMail Message: the average number of voice mail messages per month\n",
    "- Day Mins: the total number of calling during the day\n",
    "- Day Calls: the total number of calls placed during the day\n",
    "- Day Charge: the billed cost of daytime calls\n",
    "- Eve Mins, Eve Calls, Eve Charge: the billed cost for calls placed during the evening\n",
    "- Night Mins, Night Calls, Night Charge: the billed cost for calls placed during nighttime\n",
    "- Intl Mins, Intl Calls, Intl Charge: the billed cost for international calls\n",
    "- CustServ Calls: the number of calls placed to Customer Service\n",
    "- Churn?: whether the customer left the service: true/false. This is the target attribute and we will use as the label for our ML model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do some initial data cleaining. The detailed data exploration for this dataset can be found in [1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn = churn.drop('Phone', axis=1)\n",
    "churn = churn.drop(['Day Charge', 'Eve Charge', 'Night Charge', 'Intl Charge'], axis=1)\n",
    "churn['Area Code'] = churn['Area Code'].astype(object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to also convert our categorical features into numeric features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = pd.get_dummies(churn)\n",
    "model_data = pd.concat([model_data['Churn?_True.'], model_data.drop(['Churn?_False.', 'Churn?_True.'], axis=1)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the data is ready for experimentation. Let's start the first experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Experiment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good way to associaite a new experiment with a head of git is to make a new git branch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! git checkout -b experiment1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets prepare the training/validation/test datasets for for experiment 1 and push it to our storage (S3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_validate_test_split(df, train_percent=.6, validate_percent=.2, seed=None):\n",
    "    np.random.seed(seed)\n",
    "    perm = np.random.permutation(df.index)\n",
    "    m = len(df.index)\n",
    "    train_end = int(train_percent * m)\n",
    "    validate_end = int(validate_percent * m) + train_end\n",
    "    train = df.iloc[perm[:train_end]]\n",
    "    validate = df.iloc[perm[train_end:validate_end]]\n",
    "    test = df.iloc[perm[validate_end:]]\n",
    "    return train, validate, test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, validation_data, test_data = train_validate_test_split(model_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_csv('train.csv', header=False, index=False)\n",
    "validation_data.to_csv('validation.csv', header=False, index=False)\n",
    "test_data.to_csv('test.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'train/train.csv')).upload_file('train.csv')\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'validation/validation.csv')).upload_file('validation.csv')\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'test/test.csv')).upload_file('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! dvc status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets add these changes into dvc and git."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! dvc add --external s3://BUCKETNAME/sagemaker/train # Replace the bucket name with your bucket name\n",
    "! dvc add --external s3://BUCKETNAME/sagemaker/validation # Replace the bucket name with your bucket name\n",
    "! dvc add --external s3://BUCKETNAME/sagemaker/test # Replace the bucket name with your bucket name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! git add train.dvc validation.dvc test.dvc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! git commit -m \"train/val/test datasets are ready for experiment 1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! git push --set-upstream origin experiment1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's capture the commit id. We will use it later to associate it to the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! git log --format=\"%H\" -n 1   # Get commit id for data version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, in order to track this experiment in Sagemaker, we need to create an experiment. We need to also define the trial within the experiment. For the sake of simplicity, we just consider one trial for the experiment, but we can have any number of trials within an experiment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_date = strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "\n",
    "my_experiment = experiment.Experiment.create(experiment_name = \"experiment1-{}\".format(create_date),\n",
    "                                    description = \"experiment1-{}\".format(create_date)\n",
    "                                    )\n",
    "my_trial = my_experiment.create_trial(trial_name = \"trial1-{}\".format(create_date))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To track extra metadata related to a trial, we can use TrialComponent as below. For the purpose of this demo, we create a preprocessing component to track parameters (e.g. train_test_split_ratio) related to preprocessing stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "se = boto3.Session()\n",
    "sm   = se.client('sagemaker')\n",
    "\n",
    "\n",
    "with Tracker.create(display_name=\"Preprocessing\", sagemaker_boto_client=sm) as tracker:\n",
    " tracker.log_parameters({\n",
    " \"train_test_split_ratio\": 0.6\n",
    " })\n",
    "my_trial.add_trial_component(tracker.trial_component)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To track the data version in SageMaker experiment, we add the git commit id (captured before) as a parameter of this trial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_commit_id = 'COMMITID' # Enter the CommitID for data version\n",
    "\n",
    "with Tracker.create(display_name=\"DatasetLineage\", sagemaker_boto_client=sm) as ptracker:\n",
    "    ptracker.log_parameters({\"dataset_commit_id\": dataset_commit_id})\n",
    "\n",
    "my_trial.add_trial_component(ptracker.trial_component)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's run the training job. To predict the customer churining, we will use XGBoost algorithm. Let's import the container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "container = get_image_uri(boto3.Session().region_name, 'xgboost')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to also specify the location of training and validation datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_input_train = sagemaker.s3_input(s3_data='s3://{}/{}/train'.format(bucket, prefix), content_type='csv')\n",
    "s3_input_validation = sagemaker.s3_input(s3_data='s3://{}/{}/validation/'.format(bucket, prefix), content_type='csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = sagemaker.Session()\n",
    "\n",
    "xgb = sagemaker.estimator.Estimator(container,\n",
    "                                    role, \n",
    "                                    train_instance_count=1, \n",
    "                                    train_instance_type='ml.m4.xlarge',\n",
    "                                    output_path='s3://{}/{}/output'.format(bucket, prefix),\n",
    "                                    sagemaker_session=sess\n",
    "                                    #,train_use_spot_instances=True,\n",
    "                                    #train_max_wait=86400,\n",
    "                                    #subnets = ['subnet-0f9914042f9a20cad'],\n",
    "                                    #security_group_ids = ['sg-089715a9429257862'],\n",
    "                                    )\n",
    "xgb.set_hyperparameters(max_depth=5,\n",
    "                        eta=0.2,\n",
    "                        gamma=4,\n",
    "                        min_child_weight=6,\n",
    "                        subsample=0.8,\n",
    "                        silent=0,\n",
    "                        objective='binary:logistic',\n",
    "                        num_round=100)\n",
    "\n",
    "xgb.fit({'train': s3_input_train, 'validation': s3_input_validation}, experiment_config={\n",
    "            \"ExperimentName\": my_experiment.experiment_name,\n",
    "            \"TrialName\": my_trial.trial_name,\n",
    "            \"TrialComponentDisplayName\": \"Training\",\n",
    "        },)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the training job is finished, the model will be pushed to S3. Let's source control the model using dvc and associaite it to experiment 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! dvc add --external s3://BUCKETNAME/sagemaker/output # Replace the bucket name with your bucket name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! git add output.dvc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! git commit -m \" push the model for experiment 1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! git push "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! git log --format=\"%H\" -n 1   # Get commit id for model version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_commit_id =  'COMMITID' # Enter your CommitID here\n",
    "\n",
    "with Tracker.create(display_name=\"ModelLineage\", sagemaker_boto_client=sm) as mtracker:\n",
    "\n",
    "    mtracker.log_parameters({\"model_commit_id\": model_commit_id})\n",
    "\n",
    "my_trial.add_trial_component(mtracker.trial_component)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, Our first experiment is done. we easily version the data and model (via dvc), capture all the observations in sagemaker experiment. To get these observations and put it into dataframe, we can use analytics class in sagemaker as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_component_analytics = analytics.ExperimentAnalytics(experiment_name=my_experiment.experiment_name)\n",
    "experiment1_obs = trial_component_analytics.dataframe()\n",
    "experiment1_obs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Experiment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets create the second experiment through the same process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M\t.dvc/.gitignore\n",
      "M\t.dvc/config\n",
      "M\t.dvc/plots/confusion.json\n",
      "M\t.dvc/plots/default.json\n",
      "M\t.dvc/plots/scatter.json\n",
      "M\t.dvc/plots/smooth.json\n",
      "M\t.dvcignore\n",
      "M\tREADME.md\n",
      "M\tdata.dvc\n",
      "Switched to a new branch 'experiment2'\n",
      "  0% Checkout|                                       |0/1 [00:00<?,     ?file/s]\n",
      "!\u001b[A\n",
      "  0%|          |Computing file/dir hashes (only done o0/1 [00:00<?,      ?md5/s]\u001b[A\n",
      "\u001b[0m                                                                            \u001b[A"
     ]
    }
   ],
   "source": [
    "! git checkout -b experiment2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this experiment, we just drop one of the column from the original dataset to model a dataset change. Let's follow the same procedure as experiment 1 to push the data into S3 and track the changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = model_data.drop(['Account Length'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, validation_data, test_data = train_validate_test_split(model_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_csv('train.csv', header=False, index=False)\n",
    "validation_data.to_csv('validation.csv', header=False, index=False)\n",
    "test_data.to_csv('test.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'train/train.csv')).upload_file('train.csv')\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'validation/validation.csv')).upload_file('validation.csv')\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'test/test.csv')).upload_file('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! dvc add --external s3://BUCKETNAME/sagemaker/train # Replace the bucket name with your bucket name\n",
    "! dvc add --external s3://BUCKETNAME/sagemaker/validation # Replace the bucket name with your bucket name\n",
    "! dvc add --external s3://BUCKETNAME/sagemaker/test # Replace the bucket name with your bucket name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! git add train.dvc validation.dvc test.dvc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! git commit -m \"train/val/test datasets are ready for experiment 2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! git push --set-upstream origin experiment2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! git log --format=\"%H\" -n 1   # Get commit id for data version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_date = strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "\n",
    "my_experiment = experiment.Experiment.create(experiment_name = \"experiment2-{}\".format(create_date),\n",
    "                                    description = \"experiment2-{}\".format(create_date)\n",
    "                                    )\n",
    "my_trial = my_experiment.create_trial(trial_name = \"trial1-{}\".format(create_date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Tracker.create(display_name=\"Preprocessing\", sagemaker_boto_client=sm) as tracker:\n",
    " tracker.log_parameters({\n",
    " \"train_test_split_ratio\": 0.6\n",
    " })\n",
    "my_trial.add_trial_component(tracker.trial_component)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_commit_id = 'COMMITID' # Enter the CommitID for data version\n",
    "\n",
    "with Tracker.create(display_name=\"DatasetLineage\", sagemaker_boto_client=sm) as ptracker:\n",
    "    ptracker.log_parameters({\"dataset_commit_id\": dataset_commit_id})\n",
    "\n",
    "my_trial.add_trial_component(ptracker.trial_component)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = sagemaker.Session()\n",
    "\n",
    "xgb = sagemaker.estimator.Estimator(container,\n",
    "                                    role, \n",
    "                                    train_instance_count=1, \n",
    "                                    train_instance_type='ml.m4.xlarge',\n",
    "                                    output_path='s3://{}/{}/output'.format(bucket, prefix),\n",
    "                                    sagemaker_session=sess\n",
    "                                    #,train_use_spot_instances=True,\n",
    "                                    #train_max_wait=86400,\n",
    "                                    #subnets = ['subnet-0f9914042f9a20cad'],\n",
    "                                    #security_group_ids = ['sg-089715a9429257862'],\n",
    "                                    )\n",
    "xgb.set_hyperparameters(max_depth=5,\n",
    "                        eta=0.2,\n",
    "                        gamma=4,\n",
    "                        min_child_weight=6,\n",
    "                        subsample=0.8,\n",
    "                        silent=0,\n",
    "                        objective='binary:logistic',\n",
    "                        num_round=100)\n",
    "\n",
    "xgb.fit({'train': s3_input_train, 'validation': s3_input_validation}, experiment_config={\n",
    "            \"ExperimentName\": my_experiment.experiment_name,\n",
    "            \"TrialName\": my_trial.trial_name,\n",
    "            \"TrialComponentDisplayName\": \"Training\",\n",
    "        },)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! dvc add --external s3://BUCKETNAME/sagemaker/output # Replace the bucket name with your bucket name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! git add output.dvc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! git commit -m \" push the model for experiment 2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! git push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! git log --format=\"%H\" -n 1   # Get commit id for model version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_commit_id =  '5c227f6eb6562e22a077453c76dbe94139a0b92f' # Enter your CommitID here\n",
    "\n",
    "with Tracker.create(display_name=\"ModelLineage\", sagemaker_boto_client=sm) as mtracker:\n",
    "\n",
    "    mtracker.log_parameters({\"model_commit_id\": model_commit_id})\n",
    "\n",
    "my_trial.add_trial_component(mtracker.trial_component)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_component_analytics = analytics.ExperimentAnalytics(experiment_name=my_experiment.experiment_name)\n",
    "experiment2_obs = trial_component_analytics.dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have two experiments which are tracked and version controlled. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Compare the experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment1_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment2_obs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the average validation error for each experiemnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment1_obs['validation:error - Avg'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment2_obs['validation:error - Avg'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Change the artifact version "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We can easily check out to experiment1 brnach and the dataset and model will also change to the version of this experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! git checkout experiment1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the commit id to go back to a specific version of a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! git checkout d72fd71ac8ffedb6b5b8c0492e8dcc5ac0e8610b train.dvc\n",
    "! dvc pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we demonstrated how to use Amazon SageMaker experiment and DVC to keep track of ML experiemtnation artifcats (datasets, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Refrence\n",
    "\n",
    "1- https://github.com/awslabs/amazon-sagemaker-examples/blob/master/introduction_to_applying_machine_learning/xgboost_customer_churn/xgboost_customer_churn.ipynb"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}